{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ce61ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split, GridSearchCV\n",
    "from sklearn.metrics import get_scorer\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "import joblib\n",
    "from scipy.stats import randint, uniform\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0fd55f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_training = pd.read_csv('..\\\\data\\\\training_dataset.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc87a5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = dataset_training['movie_score'].values\n",
    "dataset_training = dataset_training.drop(columns=['movie_score', 'Unnamed: 0', 'Unnamed: 0.1', 'averageRating', 'numVotes', '_orig_order'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa25614c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = dataset_training.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3da733e",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 42\n",
    "n_jobs = -1\n",
    "cv = 3\n",
    "early_stopping_rounds = 50\n",
    "test_size_for_earlystop = 0.10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edfb08b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBRegressor(\n",
    "    objective='reg:squarederror',\n",
    "    tree_method='hist',         # use hist + device='cuda' to enable GPU in recent xgboost\n",
    "    device='cuda',              # tells xgboost to run on CUDA device\n",
    "    verbosity=1,\n",
    "    n_jobs=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af6a0079",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dist = {\n",
    "    'max_depth': randint(4, 12),\n",
    "    'learning_rate': uniform(0.01, 0.3),\n",
    "    'subsample': uniform(0.6, 0.4),\n",
    "    'colsample_bytree': uniform(0.5, 0.5),\n",
    "    'gamma': uniform(0, 5),\n",
    "    'n_estimators': randint(100, 1000)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "797c16ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring = 'neg_root_mean_squared_error'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "487da852",
   "metadata": {},
   "outputs": [],
   "source": [
    "search = RandomizedSearchCV(\n",
    "    model,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=40,             # try 30-100 depending on budget\n",
    "    scoring=scoring,\n",
    "    cv=cv,\n",
    "    verbose=2,\n",
    "    n_jobs=1               # 1 when GPU used\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e938547a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 40 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ander\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [15:16:17] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"predictor\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ander\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\xgboost\\core.py:774: UserWarning: [15:16:19] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:62: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  return func(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.7651535844797487, gamma=2.1606928503548906, learning_rate=0.18006080070337502, max_depth=4, n_estimators=916, subsample=0.8579617882128325; total time=   5.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ander\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [15:16:22] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"predictor\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.7651535844797487, gamma=2.1606928503548906, learning_rate=0.18006080070337502, max_depth=4, n_estimators=916, subsample=0.8579617882128325; total time=   5.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ander\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [15:16:27] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"predictor\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.7651535844797487, gamma=2.1606928503548906, learning_rate=0.18006080070337502, max_depth=4, n_estimators=916, subsample=0.8579617882128325; total time=   5.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ander\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [15:16:32] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"predictor\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.639664715839128, gamma=1.4353971484134964, learning_rate=0.29238578256770825, max_depth=5, n_estimators=264, subsample=0.856856344499076; total time=   3.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ander\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [15:16:36] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"predictor\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.639664715839128, gamma=1.4353971484134964, learning_rate=0.29238578256770825, max_depth=5, n_estimators=264, subsample=0.856856344499076; total time=   3.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ander\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [15:16:39] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"predictor\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.639664715839128, gamma=1.4353971484134964, learning_rate=0.29238578256770825, max_depth=5, n_estimators=264, subsample=0.856856344499076; total time=   3.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ander\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [15:16:43] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"predictor\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.6874212088583656, gamma=1.3044261079261643, learning_rate=0.054951859566962, max_depth=11, n_estimators=239, subsample=0.6466420880385741; total time=   5.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ander\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [15:16:49] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"predictor\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.6874212088583656, gamma=1.3044261079261643, learning_rate=0.054951859566962, max_depth=11, n_estimators=239, subsample=0.6466420880385741; total time=   5.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ander\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [15:16:54] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"predictor\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.6874212088583656, gamma=1.3044261079261643, learning_rate=0.054951859566962, max_depth=11, n_estimators=239, subsample=0.6466420880385741; total time=   5.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ander\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [15:17:00] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"predictor\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.5864683885152226, gamma=1.7642594146654278, learning_rate=0.05541860108701348, max_depth=4, n_estimators=350, subsample=0.8486400515353809; total time=   3.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ander\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [15:17:04] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"predictor\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.5864683885152226, gamma=1.7642594146654278, learning_rate=0.05541860108701348, max_depth=4, n_estimators=350, subsample=0.8486400515353809; total time=   3.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ander\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [15:17:07] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"predictor\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.5864683885152226, gamma=1.7642594146654278, learning_rate=0.05541860108701348, max_depth=4, n_estimators=350, subsample=0.8486400515353809; total time=   3.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ander\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [15:17:11] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"predictor\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.7922735184170171, gamma=4.699650367871526, learning_rate=0.18819573853812338, max_depth=4, n_estimators=252, subsample=0.8909379723459725; total time=   3.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ander\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [15:17:14] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"predictor\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.7922735184170171, gamma=4.699650367871526, learning_rate=0.18819573853812338, max_depth=4, n_estimators=252, subsample=0.8909379723459725; total time=   3.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ander\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [15:17:18] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"predictor\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.7922735184170171, gamma=4.699650367871526, learning_rate=0.18819573853812338, max_depth=4, n_estimators=252, subsample=0.8909379723459725; total time=   3.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ander\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [15:17:21] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"predictor\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.6525930463551308, gamma=4.716586639512956, learning_rate=0.013375281611135173, max_depth=9, n_estimators=490, subsample=0.9324300950502729; total time=   7.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ander\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [15:17:28] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"predictor\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.6525930463551308, gamma=4.716586639512956, learning_rate=0.013375281611135173, max_depth=9, n_estimators=490, subsample=0.9324300950502729; total time=   7.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ander\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [15:17:36] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"predictor\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.6525930463551308, gamma=4.716586639512956, learning_rate=0.013375281611135173, max_depth=9, n_estimators=490, subsample=0.9324300950502729; total time=   7.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ander\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [15:17:43] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"predictor\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.8612011649967218, gamma=1.4288123633804424, learning_rate=0.11581019740445155, max_depth=11, n_estimators=407, subsample=0.7632948906111245; total time=   8.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ander\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [15:17:52] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"predictor\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    }
   ],
   "source": [
    "search.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7b54c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results = pd.DataFrame(searcher.cv_results_).sort_values('rank_test_score').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b6224d",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = searcher.best_params_\n",
    "best_score = searcher.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79bac0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cast_simple_types(d):\n",
    "    out = {}\n",
    "    for k, v in d.items():\n",
    "        if isinstance(v, (np.integer,)):\n",
    "            out[k] = int(v)\n",
    "        elif isinstance(v, (np.floating,)):\n",
    "            out[k] = float(v)\n",
    "        else:\n",
    "            out[k] = v\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c76638",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_params = cast_simple_types(best_params)\n",
    "final_params['n_estimators'] = max(int(final_params.get('n_estimators', 200)), 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642deef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = XGBRegressor(objective='reg:squarederror', verbosity=0, random_state=random_state, **final_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fdbe8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_full, X_val, y_train_full, y_val = train_test_split(\n",
    "    x, y, test_size=test_size_for_earlystop, random_state=random_state\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0d3e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model.fit(\n",
    "    X_train_full, y_train_full,\n",
    "    eval_set=[(X_val, y_val)],\n",
    "    early_stopping_rounds=early_stopping_rounds,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20d02e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_ntree_limit = getattr(final_model, \"best_ntree_limit\", None) or getattr(final_model, \"best_iteration\", None)\n",
    "if best_ntree_limit is not None:\n",
    "    print(f\"\\nBest ntree limit found via early stopping: {best_ntree_limit}\")\n",
    "    print(\"Refitting on entire dataset using best number of trees...\")\n",
    "    final_model.set_params(n_estimators=int(best_ntree_limit))\n",
    "    final_model.fit(x, y, verbose=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793a7bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(final_model, \"xgb_reg_movie_score.joblib\")\n",
    "cv_results.to_csv(\"xgb_cv_results_movie_score.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ca3a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "fi = final_model.get_booster().get_score(importance_type='gain')\n",
    "fi_df = pd.DataFrame.from_dict(fi, orient='index', columns=['gain']).sort_values('gain', ascending=False)\n",
    "fi_df.index.name = 'feature'\n",
    "fi_df.reset_index(inplace=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
