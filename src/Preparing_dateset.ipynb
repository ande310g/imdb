{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "140759fc",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4db0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import heapq\n",
    "from typing import List, Optional\n",
    "import sklearn.preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "947c8599",
   "metadata": {},
   "source": [
    "### Load data from the merged TSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f640755d",
   "metadata": {},
   "outputs": [],
   "source": [
    "merging_tsv_files_data = pd.read_csv('..\\\\data\\\\merging_tsv_files_data.csv', sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a7e1173",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee695ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cumulative_top3_prior(group: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    For each row in an actor group, emit the top-3 *prior* ratings (and titles) before this row.\n",
    "    Uses a size-3 min-heap for O(n) per group.\n",
    "    \"\"\"\n",
    "    top_heap = []  # min-heap of (rating, title) so smallest on top; keep size<=3\n",
    "    prior1_rating, prior2_rating, prior3_rating = [], [], []\n",
    "\n",
    "    for _, row in group.iterrows():\n",
    "        # snapshot current top prior works (sorted desc)\n",
    "        snapshot = sorted(top_heap, key=lambda x: x[0], reverse=True)\n",
    "        ratings = [r for r, _ in snapshot]\n",
    "\n",
    "        # pad to length 3\n",
    "        while len(ratings) < 3:\n",
    "            ratings.append(np.nan)\n",
    "\n",
    "        prior1_rating.append(ratings[0])\n",
    "        prior2_rating.append(ratings[1])\n",
    "        prior3_rating.append(ratings[2])\n",
    "        # now add current row into the actor's history\n",
    "        heapq.heappush(top_heap, (row['movie_score'], row.get('tconst', None)))\n",
    "        if len(top_heap) > 3:\n",
    "            heapq.heappop(top_heap)\n",
    "\n",
    "    out = pd.DataFrame({\n",
    "        'prior1_rating': prior1_rating,\n",
    "        'prior2_rating': prior2_rating,\n",
    "        'prior3_rating': prior3_rating,\n",
    "    }, index=group.index)\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8f48dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def make_movie_actor_wide(\n",
    "    df: pd.DataFrame,\n",
    "    *,\n",
    "    movie_id_col: str = \"tconst\",\n",
    "    actor_order_col: str = \"ordering\",\n",
    "    max_actors: int = 15,\n",
    "    actor_categories: tuple = (\"actor\", \"actress\", 'self'),\n",
    "    include_actor_text_cols: bool = True,\n",
    "    primary_name_col: str = \"primaryName\",\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Convert a long movie-actor dataset to a wide one: 1 row per movie, N actors as columns.\n",
    "    \"\"\"\n",
    "\n",
    "    df = df.copy()\n",
    "\n",
    "    # best-effort auto-detect for primary name column if exact match isn't present\n",
    "    if primary_name_col not in df.columns:\n",
    "        candidates = [c for c in df.columns if c.lower().replace(\"_\",\"\") == \"primaryname\"]\n",
    "        if len(candidates) == 1:\n",
    "            primary_name_col = candidates[0]\n",
    "\n",
    "    # Ensure ordering exists\n",
    "    if actor_order_col not in df.columns:\n",
    "        df[actor_order_col] = df.groupby(movie_id_col).cumcount() + 1\n",
    "\n",
    "    # Filter to actors only (if category exists)\n",
    "    if \"category\" in df.columns and actor_categories:\n",
    "        df = df[df[\"category\"].isin(actor_categories)].copy()\n",
    "\n",
    "    # Sort so 'first()' is first-billed for movie-level fields\n",
    "    df = df.sort_values([movie_id_col, actor_order_col], kind=\"mergesort\")\n",
    "\n",
    "    # Define movie-level columns (keep once per movie)\n",
    "    actor_level_cols = {\n",
    "        \"nconst\", primary_name_col,\n",
    "        \"actor_sentiment\", \"prior_movie_actor_sentiment\",\n",
    "        \"prior1_rating\", \"prior2_rating\", \"prior3_rating\",\n",
    "        actor_order_col\n",
    "    }\n",
    "    movie_level_cols = [c for c in df.columns if c not in actor_level_cols]\n",
    "\n",
    "    # Base movie table\n",
    "    movie_base = df.groupby(movie_id_col, as_index=False)[movie_level_cols].first()\n",
    "\n",
    "    # Assign actor index and cap at N\n",
    "    df[\"actor_idx\"] = df.groupby(movie_id_col).cumcount() + 1\n",
    "    df = df[df[\"actor_idx\"] <= max_actors].copy()\n",
    "\n",
    "    # Select actor features\n",
    "    actor_feature_cols = [\n",
    "        \"actor_sentiment\",\n",
    "        \"prior_movie_actor_sentiment\",\n",
    "        \"prior1_rating\", \"prior2_rating\", \"prior3_rating\",\n",
    "    ]\n",
    "    if include_actor_text_cols:\n",
    "        actor_feature_cols = [\"nconst\", primary_name_col] + actor_feature_cols\n",
    "\n",
    "    keep_cols = [movie_id_col, \"actor_idx\"] + [c for c in actor_feature_cols if c in df.columns]\n",
    "    actors_narrow = df[keep_cols].copy()\n",
    "\n",
    "    # Pivot wide\n",
    "    actors_wide = (\n",
    "        actors_narrow\n",
    "        .set_index([movie_id_col, \"actor_idx\"])\n",
    "        .unstack(\"actor_idx\")\n",
    "    )\n",
    "\n",
    "    # Flatten MultiIndex columns: (feature, idx) -> f\"actor{idx}_{feature}\"\n",
    "    actors_wide.columns = [f\"actor{idx}_{name}\" for name, idx in actors_wide.columns]\n",
    "    actors_wide = actors_wide.reset_index()\n",
    "\n",
    "    # Merge back\n",
    "    wide_df = movie_base.merge(actors_wide, on=movie_id_col, how=\"left\")\n",
    "\n",
    "    # Order columns: movie fields first, then actors by idx\n",
    "    movie_cols_first = list(movie_base.columns)\n",
    "    actor_cols_after = sorted(\n",
    "        [c for c in wide_df.columns if c not in movie_cols_first],\n",
    "        key=lambda x: (int(x.split(\"_\")[0].replace(\"actor\", \"\")), x)\n",
    "    )\n",
    "    wide_df = wide_df[movie_cols_first + actor_cols_after]\n",
    "\n",
    "    return wide_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f86625",
   "metadata": {},
   "source": [
    "# Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c326116",
   "metadata": {},
   "outputs": [],
   "source": [
    "simpel_dataset = merging_tsv_files_data.drop(labels = [merging_tsv_files_data.columns[0], merging_tsv_files_data.columns[1], 'writers', 'characters', 'primaryProfession', 'birthYear', 'deathYear', 'known_for_movie_1', 'known_for_movie_2', 'known_for_movie_3', 'known_for_movie_4'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e930752",
   "metadata": {},
   "source": [
    "#### Calculating movie score and an actor sentiment score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611a52c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "simpel_dataset['movie_score'] = simpel_dataset['averageRating'] * simpel_dataset['numVotes']\n",
    "simpel_dataset['actor_sentiment'] = simpel_dataset['movie_score']/simpel_dataset['ordering']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77204d21",
   "metadata": {},
   "source": [
    "### Remove duplicate actors per movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d977b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "simpel_dataset = simpel_dataset.drop_duplicates(subset=['tconst', 'nconst'])\n",
    "simpel_dataset = simpel_dataset.sort_values(['tconst', 'ordering'])\n",
    "simpel_dataset['ordering'] = simpel_dataset.groupby('tconst').cumcount() + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5275628f",
   "metadata": {},
   "source": [
    "#### Calculating actors prior movie sentiment scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a602d6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "simpel_dataset['_orig_order'] = np.arange(len(simpel_dataset))  # to break same-date ties\n",
    "simpel_dataset = simpel_dataset.sort_values(['primaryName', 'startYear', '_orig_order'], kind='mergesort')\n",
    "simpel_dataset['prior_movie_actor_sentiment'] = simpel_dataset.groupby('primaryName')['actor_sentiment'].transform(lambda x: x.cumsum() - x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e25ff54",
   "metadata": {},
   "source": [
    "#### Converting strings to int "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ee8802",
   "metadata": {},
   "outputs": [],
   "source": [
    "simpel_dataset['startYear'] = simpel_dataset['startYear'].replace('\\\\N', np.nan)\n",
    "simpel_dataset['startYear'] = pd.to_numeric(simpel_dataset['startYear'], errors='coerce')\n",
    "simpel_dataset['startYear'] = np.floor(simpel_dataset['startYear'])\n",
    "simpel_dataset['startYear'] = simpel_dataset['startYear'].astype('Int64')\n",
    "simpel_dataset['runtimeMinutes'] = simpel_dataset['runtimeMinutes'].replace('\\\\N', np.nan)\n",
    "simpel_dataset['runtimeMinutes'] = pd.to_numeric(simpel_dataset['runtimeMinutes'], errors='coerce')\n",
    "simpel_dataset['runtimeMinutes'] = np.floor(simpel_dataset['runtimeMinutes'])\n",
    "simpel_dataset['runtimeMinutes'] = simpel_dataset['runtimeMinutes'].astype('Int64')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78cdabe8",
   "metadata": {},
   "source": [
    "#### Calculating prior known for movies per actor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229ebcdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "simpel_dataset = simpel_dataset.sort_values(['primaryName', 'startYear', '_orig_order'], kind='mergesort')\n",
    "aug = simpel_dataset.groupby('primaryName', group_keys=False).apply(cumulative_top3_prior)\n",
    "simpel_dataset = simpel_dataset.join(aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f05431f",
   "metadata": {},
   "outputs": [],
   "source": [
    "simpel_dataset.to_csv('..\\\\data\\\\interrim_data1.csv', sep =';')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44667dab",
   "metadata": {},
   "source": [
    "## One row per movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a4f073d",
   "metadata": {},
   "outputs": [],
   "source": [
    "simpel_dataset = pd.read_csv('..\\\\data\\\\interrim_data.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0b781c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_actors = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8841e2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "wide_df = make_movie_actor_wide(simpel_dataset, max_actors=num_actors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "478252c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "wide_df.to_csv('..\\\\data\\\\dataset.csv', sep =';')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
