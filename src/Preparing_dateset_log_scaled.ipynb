{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "140759fc",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c4db0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import heapq\n",
    "from typing import List, Optional"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d954e570",
   "metadata": {},
   "source": [
    "## Script variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6fd676c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_actors = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "947c8599",
   "metadata": {},
   "source": [
    "### Load data from the merged TSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f640755d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ander\\AppData\\Local\\Temp\\ipykernel_16924\\4181670877.py:3: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  merging_tsv_files_data = pd.read_csv(pathToMergedFiles, sep=';')\n"
     ]
    }
   ],
   "source": [
    "useBackslash = True\n",
    "pathToMergedFiles = r'..\\data\\merging_tsv_files_data.csv' if useBackslash  else r'../data/merging_tsv_files_data.csv'\n",
    "merging_tsv_files_data = pd.read_csv(pathToMergedFiles, sep=';')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a7e1173",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aadd4849",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cumulative_top3_prior(\n",
    "    group: pd.DataFrame,\n",
    "    director: bool = False,\n",
    "    key_cols: tuple = (\"directors\", \"tconst\"),   # or (\"tconst\", \"nconst\")\n",
    "):\n",
    "    \"\"\"\n",
    "    For each row in a group, emit the top-3 *prior* movie_score values before this row.\n",
    "    Returns a DataFrame aligned to group.index and includes key_cols for safe merges.\n",
    "    \"\"\"\n",
    "\n",
    "    # Min-heap that stores at most 3 tuples of (movie_score, tconst)\n",
    "    # This always represents the current top-3 movie scores seen so far\n",
    "    top_heap = []\n",
    "\n",
    "    # Lists that will store the 1st, 2nd, and 3rd highest PRIOR ratings per row\n",
    "    prior1, prior2, prior3 = [], [], []\n",
    "\n",
    "    # IMPORTANT: iterate row-by-row in the existing order of `group`\n",
    "    # The meaning of \"prior\" depends on this order already being correct\n",
    "    for _, row in group.iterrows():\n",
    "\n",
    "        # Take a snapshot of the heap BEFORE adding the current row\n",
    "        # Sort descending so highest scores come first\n",
    "        snapshot = sorted(top_heap, key=lambda x: x[0], reverse=True)\n",
    "\n",
    "        # Extract only the movie_score values from the snapshot\n",
    "        ratings = [r for r, _ in snapshot]\n",
    "\n",
    "        # Ensure exactly three values (pad with NaN if fewer than 3 exist)\n",
    "        while len(ratings) < 3:\n",
    "            ratings.append(np.nan)\n",
    "\n",
    "        # Store the top-1, top-2, and top-3 PRIOR ratings for this row\n",
    "        prior1.append(ratings[0])\n",
    "        prior2.append(ratings[1])\n",
    "        prior3.append(ratings[2])\n",
    "\n",
    "        # Add the current row's movie_score to the heap\n",
    "        # This happens AFTER collecting prior values\n",
    "        heapq.heappush(top_heap, (row[\"movie_score\"], row.get(\"tconst\", None)))\n",
    "\n",
    "        # Keep only the top 3 scores in the heap\n",
    "        if len(top_heap) > 3:\n",
    "            heapq.heappop(top_heap)\n",
    "\n",
    "    # Create an output DataFrame with the SAME index as the input group\n",
    "    # This guarantees perfect row alignment\n",
    "    out = pd.DataFrame(index=group.index)\n",
    "\n",
    "    # Copy key columns directly from the input group\n",
    "    # These allow safe merges back to the original dataset\n",
    "    for c in key_cols:\n",
    "        if c not in group.columns:\n",
    "            raise KeyError(\n",
    "                f\"Key column '{c}' not found in group columns: {list(group.columns)}\"\n",
    "            )\n",
    "        out[c] = group[c].values\n",
    "\n",
    "    # Choose column name suffix depending on whether this is for directors or actors\n",
    "    suffix = \"_director\" if director else \"_actor\"\n",
    "\n",
    "    # Attach the computed prior-rating columns\n",
    "    out[f\"prior1_rating{suffix}\"] = prior1\n",
    "    out[f\"prior2_rating{suffix}\"] = prior2\n",
    "    out[f\"prior3_rating{suffix}\"] = prior3\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8691a879",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_movie_actor_wide(\n",
    "    df: pd.DataFrame,\n",
    "    *,\n",
    "    movie_id_col: str = \"tconst\",\n",
    "    actor_order_col: str = \"ordering\",\n",
    "    max_actors: int = 15,\n",
    "    actor_categories: tuple = (\"actor\", \"actress\", \"self\"),\n",
    "    include_actor_text_cols: bool = True,\n",
    "    primary_name_col: str = \"primaryName\",\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Convert a long movie-actor dataset to a wide one: 1 row per movie, N actors as columns.\n",
    "    \"\"\"\n",
    "\n",
    "    # Work on a copy so the caller's DataFrame is not modified in-place.\n",
    "    df = df.copy()\n",
    "\n",
    "    # Best-effort auto-detect for the actor name column if the exact column name isn't present.\n",
    "    # (e.g., handles variations like \"primary_name\" vs \"primaryName\".)\n",
    "    if primary_name_col not in df.columns:\n",
    "        candidates = [c for c in df.columns if c.lower().replace(\"_\", \"\") == \"primaryname\"]\n",
    "        if len(candidates) == 1:\n",
    "            primary_name_col = candidates[0]  # use the one unambiguous match found\n",
    "\n",
    "    # Ensure an ordering column exists (used to define \"top billed\" actor positions).\n",
    "    # If missing, create it per movie using row order within each movie group (1..N).\n",
    "    if actor_order_col not in df.columns:\n",
    "        df[actor_order_col] = df.groupby(movie_id_col).cumcount() + 1\n",
    "\n",
    "    # If a \"category\" column exists, keep only rows matching actor_categories\n",
    "    # (filters out crew jobs, etc.). If actor_categories is falsy, skip filtering.\n",
    "    if \"category\" in df.columns and actor_categories:\n",
    "        df = df[df[\"category\"].isin(actor_categories)].copy()\n",
    "\n",
    "    # Sort by movie then actor ordering so that groupby(...).first() will pick:\n",
    "    # - the first-billed actor's row as the representative for movie-level fields\n",
    "    #   (important if movie-level columns are repeated on each actor row).\n",
    "    # mergesort is stable, so ties preserve original order.\n",
    "    df = df.sort_values([movie_id_col, actor_order_col], kind=\"mergesort\")\n",
    "\n",
    "    # Define columns considered \"actor-level\" (vary per actor within a movie).\n",
    "    # Everything else will be treated as \"movie-level\" (kept once per movie).\n",
    "    actor_level_cols = {\n",
    "        \"nconst\",                     # actor/person id\n",
    "        primary_name_col,             # actor name\n",
    "        # Avoid leakage: per-actor sentiment for the *current* movie is actor-level and excluded.\n",
    "        \"actor_sentiment\",\n",
    "        # These are allowed actor features because they are prior-only (historical) signals.\n",
    "        \"prior_movie_actor_sentiment\",\n",
    "        \"prior1_rating_actor\", \"prior2_rating_actor\", \"prior3_rating_actor\",\n",
    "        actor_order_col               # billing/order position\n",
    "    }\n",
    "\n",
    "    # Movie-level columns are all columns not in actor_level_cols.\n",
    "    # These will be reduced to one row per movie.\n",
    "    movie_level_cols = [c for c in df.columns if c not in actor_level_cols]\n",
    "\n",
    "    # Create a base movie table: one row per movie containing only movie-level columns.\n",
    "    # Using .first() after sorting ensures consistent selection of repeated values.\n",
    "    movie_base = df.groupby(movie_id_col, as_index=False)[movie_level_cols].first()\n",
    "\n",
    "    # Assign a 1..k index to actors within each movie (based on the sorted order),\n",
    "    # which later becomes the column suffix (actor1_*, actor2_*, ...).\n",
    "    df[\"actor_idx\"] = df.groupby(movie_id_col).cumcount() + 1\n",
    "\n",
    "    # Cap the number of actors kept per movie to max_actors (e.g., top 15 billed).\n",
    "    df = df[df[\"actor_idx\"] <= max_actors].copy()\n",
    "\n",
    "    # Choose actor features to pivot into wide format.\n",
    "    # These are \"prior-only\" features to reduce leakage risk.\n",
    "    actor_feature_cols = [\n",
    "        \"prior_movie_actor_sentiment\",\n",
    "        \"prior1_rating_actor\", \"prior2_rating_actor\", \"prior3_rating_actor\",\n",
    "    ]\n",
    "\n",
    "    # Optionally include text/id columns for each actor (nconst + primary name).\n",
    "    if include_actor_text_cols:\n",
    "        actor_feature_cols = [\"nconst\", primary_name_col] + actor_feature_cols\n",
    "\n",
    "    # Keep only columns needed for the pivot:\n",
    "    # - movie id\n",
    "    # - actor index within the movie\n",
    "    # - whichever actor_feature_cols actually exist in df (guards missing columns)\n",
    "    keep_cols = [movie_id_col, \"actor_idx\"] + [c for c in actor_feature_cols if c in df.columns]\n",
    "    actors_narrow = df[keep_cols].copy()\n",
    "\n",
    "    # Pivot from narrow (one row per movie-actor) to wide (one row per movie).\n",
    "    # After unstack, columns become a MultiIndex like: (feature_name, actor_idx).\n",
    "    actors_wide = (\n",
    "        actors_narrow\n",
    "        .set_index([movie_id_col, \"actor_idx\"])\n",
    "        .unstack(\"actor_idx\")\n",
    "    )\n",
    "\n",
    "    # Flatten the MultiIndex columns: (feature, idx) -> \"actor{idx}_{feature}\"\n",
    "    # Example: (\"nconst\", 2) -> \"actor2_nconst\"\n",
    "    actors_wide.columns = [f\"actor{idx}_{name}\" for name, idx in actors_wide.columns]\n",
    "\n",
    "    # Bring movie_id_col back as a normal column for merging.\n",
    "    actors_wide = actors_wide.reset_index()\n",
    "\n",
    "    # Merge the per-movie base table with the actor-wide features.\n",
    "    # Left join keeps all movies even if some have fewer than max_actors actors.\n",
    "    wide_df = movie_base.merge(actors_wide, on=movie_id_col, how=\"left\")\n",
    "\n",
    "    # Reorder columns so movie-level fields come first.\n",
    "    movie_cols_first = list(movie_base.columns)\n",
    "\n",
    "    # Then order actor columns by actor index first (actor1_..., actor2_..., etc.),\n",
    "    # and within the same actor index, sort by the full column name for stability.\n",
    "    actor_cols_after = sorted(\n",
    "        [c for c in wide_df.columns if c not in movie_cols_first],\n",
    "        key=lambda x: (int(x.split(\"_\")[0].replace(\"actor\", \"\")), x)\n",
    "    )\n",
    "    wide_df = wide_df[movie_cols_first + actor_cols_after]\n",
    "\n",
    "    return wide_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f86625",
   "metadata": {},
   "source": [
    "# Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70194d08",
   "metadata": {},
   "source": [
    "#### Drop unwanted columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c326116",
   "metadata": {},
   "outputs": [],
   "source": [
    "simpel_dataset = merging_tsv_files_data.drop(labels = [merging_tsv_files_data.columns[0], 'writers', 'characters', 'primaryProfession', 'birthYear', 'deathYear', 'known_for_movie_1', 'known_for_movie_2', 'known_for_movie_3', 'known_for_movie_4'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e930752",
   "metadata": {},
   "source": [
    "#### Calculating movie score and an actor sentiment score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "611a52c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "simpel_dataset['movie_score'] = simpel_dataset['averageRating'] * simpel_dataset['numVotes']\n",
    "simpel_dataset['actor_sentiment'] = simpel_dataset['movie_score']/simpel_dataset['ordering']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a71044c8",
   "metadata": {},
   "source": [
    "### Log transforms data for a better distribution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4fa78a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "simpel_dataset['movie_score'] = np.log1p(simpel_dataset['movie_score'])\n",
    "simpel_dataset['actor_sentiment'] = np.log1p(simpel_dataset['actor_sentiment'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e25ff54",
   "metadata": {},
   "source": [
    "#### Converting strings to int "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "33ee8802",
   "metadata": {},
   "outputs": [],
   "source": [
    "simpel_dataset['startYear'] = simpel_dataset['startYear'].replace(r'\\N', np.nan)\n",
    "simpel_dataset['startYear'] = pd.to_numeric(simpel_dataset['startYear'], errors='coerce')\n",
    "simpel_dataset['startYear'] = np.floor(simpel_dataset['startYear'])\n",
    "simpel_dataset['startYear'] = simpel_dataset['startYear'].astype('Int64')\n",
    "simpel_dataset['runtimeMinutes'] = simpel_dataset['runtimeMinutes'].replace(r'\\N', np.nan)\n",
    "simpel_dataset['runtimeMinutes'] = pd.to_numeric(simpel_dataset['runtimeMinutes'], errors='coerce')\n",
    "simpel_dataset['runtimeMinutes'] = np.floor(simpel_dataset['runtimeMinutes'])\n",
    "simpel_dataset['runtimeMinutes'] = simpel_dataset['runtimeMinutes'].astype('Int64')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9253abbe",
   "metadata": {},
   "source": [
    "#### Creating a variable to break same year ties\n",
    "The reason being an exact date isn't accessible from the date set therefore something arbitrary had replace it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "64eac0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "simpel_dataset['_orig_order'] = np.arange(len(simpel_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f97eaa2",
   "metadata": {},
   "source": [
    "#### Calculating directors prior movie sentiment and top 3 prior movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40b01c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split directors column into the different directors but only keep the first \n",
    "simpel_dataset['directors'] = simpel_dataset['directors'].str.split(',').str[0]\n",
    "# Create a seperate dataframe to remove multiple rows per movie and keeps the temporal order\n",
    "director_df = (simpel_dataset[['tconst', 'directors', 'startYear', '_orig_order', 'movie_score']]\n",
    "               .where(simpel_dataset['directors'] != r'\\N')\n",
    "               .drop_duplicates(subset=['tconst', 'directors'])\n",
    "               .sort_values(['directors', 'startYear', '_orig_order'], kind='mergesort'))\n",
    "# Calculate directors prior movie performance\n",
    "director_df['prior_movie_director_sentiment'] = director_df.groupby('directors')['movie_score'].transform(lambda x : x.cumsum()-x).fillna(0)\n",
    "# Calculate directors top 3 prior movies\n",
    "director_aug = (\n",
    "    director_df\n",
    "    .groupby(\"directors\", group_keys=False)\n",
    "    .apply(cumulative_top3_prior, director=True, key_cols=(\"directors\", \"tconst\"))\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "#Merge the director_aug and director_df \n",
    "director_df = director_df.merge(\n",
    "    director_aug,\n",
    "    on=[\"directors\", \"tconst\"],\n",
    "    how=\"left\"\n",
    ")\n",
    "# Merge director_df into the original dataframe\n",
    "simpel_dataset = simpel_dataset.merge(\n",
    "    director_df[['tconst', 'directors', 'prior_movie_director_sentiment', 'prior1_rating_director', 'prior2_rating_director', 'prior3_rating_director']], \n",
    "    on=['tconst', 'directors'], \n",
    "    how='left'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77204d21",
   "metadata": {},
   "source": [
    "### Remove duplicate actors per movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "97d977b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drops duplicates\n",
    "simpel_dataset = simpel_dataset.drop_duplicates(subset=['tconst', 'nconst'])\n",
    "# Resets ordering without duplicates but keeps the original actor ordering \n",
    "simpel_dataset = simpel_dataset.sort_values(['tconst', 'ordering'])\n",
    "simpel_dataset['ordering'] = simpel_dataset.groupby('tconst').cumcount() + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5275628f",
   "metadata": {},
   "source": [
    "#### Calculating actors prior movie sentiment scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a602d6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the data to keep the temporal order for each actor\n",
    "simpel_dataset = simpel_dataset.sort_values(['primaryName', 'startYear', '_orig_order'], kind='mergesort')\n",
    "# Calculates the prior performance for each actor\n",
    "simpel_dataset['prior_movie_actor_sentiment'] = simpel_dataset.groupby('primaryName')['actor_sentiment'].transform(lambda x: x.cumsum() - x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78cdabe8",
   "metadata": {},
   "source": [
    "#### Calculating prior known for movies per actor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229ebcdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Makes sure that the temporal order is kept just as before\n",
    "simpel_dataset = simpel_dataset.sort_values(['primaryName', 'startYear', '_orig_order'], kind='mergesort')\n",
    "# Calcultates every actors top 3 prior movies\n",
    "aug = simpel_dataset.groupby('primaryName', group_keys=False).apply(cumulative_top3_prior, director=False, key_cols=('nconst', 'tconst'))\n",
    "# Merge aug with the original dataset\n",
    "simpel_dataset = simpel_dataset.merge(aug[['tconst', 'nconst', 'prior1_rating_actor', 'prior2_rating_actor', 'prior3_rating_actor']], on=['tconst', 'nconst'], how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44667dab",
   "metadata": {},
   "source": [
    "## One row per movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8841e2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "wide_df = make_movie_actor_wide(simpel_dataset, max_actors=num_actors)\n",
    "# remove any leaked current-movie actor sentiment if present\n",
    "wide_df = wide_df.drop(columns=[\"actor_sentiment\"], errors=\"ignore\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc2d4be",
   "metadata": {},
   "source": [
    "### Calculates year since release"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c480c5a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add years since release\n",
    "# The dataset is from 2024, so we subtract the release year from 2024\n",
    "wide_df['years_since_release'] = 2024 - wide_df['startYear']\n",
    "\n",
    "# Add years since release squared\n",
    "wide_df['years_since_release_squared'] = wide_df['years_since_release'] ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "478252c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "saveDatasetAt = r'.\\common_datasets\\original_dataset_log_scaled.csv' if useBackslash else r'./common_data/original_dataset_log_scaled.csv'\n",
    "wide_df.to_csv(saveDatasetAt, sep =';')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
