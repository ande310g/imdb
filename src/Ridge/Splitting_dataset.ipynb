{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "126666f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import sklearn.preprocessing\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6906fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_missing_actor_value (df, num_actors):\n",
    "    \"\"\"This function handles missing actor values, this being actor_sentiment, and prior actor rating.\n",
    "    If there isn't an actor the value is set to -1 and if there is an actor but there isn't a value present it is set to 0.\n",
    "\n",
    "    Args:\n",
    "        df (DataFrmae): Dataframe with actor columns\n",
    "        num_actors (Int): The amount of actors in the dataframe\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: Returns an updated dataframe, the missing values have been handeled\n",
    "    \"\"\"\n",
    "    # Loop over columns\n",
    "    for i in range (1, num_actors + 1):\n",
    "        # The active actor column that is being checked\n",
    "        actor_pos = f'actor{i}_nconst'\n",
    "        # Data mask for every position where there isn't an actor in the data\n",
    "        actor_null_mask = df[actor_pos].isna()\n",
    "        # Creates an inverse of the data mask, to know where there is an actor in the data\n",
    "        actor_non_null_mask = ~actor_null_mask\n",
    "        # Sets the value to -1 if there isn't a actor present\n",
    "        df.loc[actor_null_mask, actor_pos] = -1\n",
    "        # Loops through the different columns attached to the actor\n",
    "        for suffix in ['_actor_sentiment', '_prior1_rating_actor', '_prior2_rating_actor', '_prior3_rating_actor', '_prior_movie_actor_sentiment']:\n",
    "            col_name = f'actor{i}{suffix}'\n",
    "            if col_name in df.columns:\n",
    "                # If the actor isn't present sets the value to -1\n",
    "                df.loc[actor_null_mask, col_name] = -1\n",
    "                # If the actor is present and the value in the given cell i null then 0\n",
    "                df.loc[actor_non_null_mask & df[col_name].isna(), col_name] = 0\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9590c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_missing_director_value (df):\n",
    "    \"\"\"This function handles missing director values, this being director_sentiment and prior director sentiment.\n",
    "    If there isn't a director attached to the movie then every value is set to -1 otherwise it is set to 0.\n",
    "\n",
    "    Args:\n",
    "        df (DataFrame): Dataframe with director columns\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: Returns an updated dataframe, where the values have been handled.\n",
    "    \"\"\"\n",
    "    # Data mask for every row where there isn't a director in the data\n",
    "    director_null_mask = df['directors'].isna()\n",
    "    # Inverse data mask, to know where there is a director in the data\n",
    "    director_non_null_mask = ~director_null_mask\n",
    "    df.loc[director_null_mask, 'directors'] = -1\n",
    "    # Loops through the different director columns.\n",
    "    for col_name in ['prior_movie_director_sentiment', 'prior1_rating_director', 'prior2_rating_director', 'prior3_rating_director']:\n",
    "        if col_name in df.columns:\n",
    "            # If the director isn't present in on the row then set value to -1\n",
    "            df.loc[director_null_mask, col_name] = -1\n",
    "            # If the director is present on the row but the value is null then 0.\n",
    "            df.loc[director_non_null_mask & df[col_name].isna(), col_name] = 0\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41fdced6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_mean (df, column, groupby):\n",
    "    \"\"\"Fill the empty values in the a column with the mean of a group in the column.\n",
    "\n",
    "    Args:\n",
    "        df (DataFrame): The dataframe that needs to be filled\n",
    "        column (String): The column that needs to null handled\n",
    "        groupby (String): The value that needs to be grouped by \n",
    "\n",
    "    Returns:\n",
    "        DataFrame: Updated dataframe\n",
    "    \"\"\"\n",
    "    # Groups the rows via the groupby value given, calculates the mean of that group, and fills in the null cells in the \n",
    "    df[column] = (df[column]\n",
    "                  .fillna(\n",
    "                      df.groupby(groupby)[column]\n",
    "                      .transform('mean')\n",
    "                      )\n",
    "                  )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9dcaf730",
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_runtime(df, column_name='runtime'):\n",
    "    \"\"\"Categorize \n",
    "\n",
    "    Args:\n",
    "        df (_type_): _description_\n",
    "        column_name (str, optional): _description_. Defaults to 'runtime'.\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "    # Define bins (in minutes)\n",
    "    bins = [0, 90, 120, 150, float('inf')]\n",
    "    labels = ['short', 'medium', 'long', 'very_long']\n",
    "\n",
    "    # Create a new column for runtime category and categorize them\n",
    "    df['runtime_category'] = pd.cut(df[column_name], bins=bins, labels=labels, right=False)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44d27fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode_columns(df, columns, encoder=None):\n",
    "    \"\"\"\n",
    "    One-hot encode columns. If encoder is provided, use it for transform only.\n",
    "    Otherwise, fit a new encoder.\n",
    "    Returns: (df, encoder_dict) where encoder_dict maps column names to fitted encoders\n",
    "    \"\"\"\n",
    "    encoder_dict = {}\n",
    "    for col in columns:\n",
    "        if encoder is None or col not in encoder:\n",
    "            # Fit new encoder\n",
    "            enc = sklearn.preprocessing.OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "            encoded = enc.fit_transform(df[[col]])\n",
    "            encoder_dict[col] = enc\n",
    "        else:\n",
    "            # Use provided encoder\n",
    "            enc = encoder[col]\n",
    "            encoded = enc.transform(df[[col]])\n",
    "        # Preserve original index to avoid new rows being created\n",
    "        encoded_df = pd.DataFrame(encoded, columns=enc.get_feature_names_out([col]), index=df.index)\n",
    "        # Concatenate safely\n",
    "        df = pd.concat([df.drop(col, axis=1), encoded_df], axis=1)\n",
    "    \n",
    "    return df, encoder_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cadc41d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_actors_columns(df, num_actors):\n",
    "    \"\"\"Removes unwanted actor (nconst, primaryName and sentiment) columns from the dataframe.\n",
    "\n",
    "    Args:\n",
    "        df (DataFrame): A dataframe with unwanted actor columns\n",
    "        num_actors (Int): The amount of actors in the dataframe\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: An updated dataframe, with the removed actor columns\n",
    "    \"\"\"\n",
    "    # Loops over the number over actors\n",
    "    for i in range (1, num_actors + 1):\n",
    "        # Defines columns to be removed\n",
    "        actor_id = f'actor{i}_nconst'\n",
    "        actor_name = f'actor{i}_primaryName'\n",
    "        #Drops the columns\n",
    "        df = df.drop(columns=[actor_id, actor_name])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b2526151",
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_columns(df_train, df_test):\n",
    "    \"\"\"Makes sure the testing dataset have the same amount of columns\n",
    "\n",
    "    Args:\n",
    "        df_train (DataFrame): Dataframe with training data\n",
    "        df_test (DataFrame): Dataframe with testing data\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: Testing dataframe with the same amount of columns\n",
    "    \"\"\"\n",
    "    for col in df_train.columns:\n",
    "        if col not in df_test.columns:\n",
    "            df_test[col] = 0\n",
    "    df_test = df_test[df_train.columns]\n",
    "    return df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6491ea22",
   "metadata": {},
   "source": [
    "# Split data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8abc0115",
   "metadata": {},
   "source": [
    "## Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f50bf5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_actors = 10\n",
    "split_ratio = 0.8\n",
    "columns_to_drop = ['Unnamed: 0', 'tconst', 'titleType', 'primaryTitle', 'originalTitle', 'directors', 'category', 'job']\n",
    "votes_max = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f1bfbf",
   "metadata": {},
   "source": [
    "### Retrieve data from the prepared dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fff423bf",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '..\\\\common_datasets\\\\original_dataset_log_scaled.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m useBackslash = \u001b[38;5;28;01mTrue\u001b[39;00m \n\u001b[32m      2\u001b[39m retrieveDatasetFrom = \u001b[33mr\u001b[39m\u001b[33m'\u001b[39m\u001b[33m..\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mcommon_datasets\u001b[39m\u001b[33m\\\u001b[39m\u001b[33moriginal_dataset_log_scaled.csv\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m useBackslash \u001b[38;5;28;01melse\u001b[39;00m \u001b[33mr\u001b[39m\u001b[33m'\u001b[39m\u001b[33m../common_datasets/original_dataset_log_scaled.csv\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m data = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretrieveDatasetFrom\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msep\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m;\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m data[\u001b[33m\"\u001b[39m\u001b[33mgenres_list\u001b[39m\u001b[33m\"\u001b[39m] = data[\u001b[33m\"\u001b[39m\u001b[33mgenres_list\u001b[39m\u001b[33m\"\u001b[39m].apply(\n\u001b[32m      5\u001b[39m     \u001b[38;5;28;01mlambda\u001b[39;00m x: ast.literal_eval(x) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x\n\u001b[32m      6\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages/pandas/io/parsers/readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages/pandas/io/parsers/readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages/pandas/io/parsers/readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages/pandas/io/parsers/readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages/pandas/io/common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '..\\\\common_datasets\\\\original_dataset_log_scaled.csv'"
     ]
    }
   ],
   "source": [
    "useBackslash = True \n",
    "retrieveDatasetFrom = r'..\\common_datasets\\original_dataset_log_scaled.csv' if useBackslash else r'../common_datasets/original_dataset_log_scaled.csv'\n",
    "data = pd.read_csv(retrieveDatasetFrom, sep=';')\n",
    "data[\"genres_list\"] = data[\"genres_list\"].apply(\n",
    "    lambda x: ast.literal_eval(x) if isinstance(x, str) else x\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745d4845",
   "metadata": {},
   "source": [
    "Replaces directors where the value is \\N to be able to better handle missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5214af41",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['directors'] = data['directors'].replace(r'\\N', np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf3ba68",
   "metadata": {},
   "source": [
    "### Splits the data on a given year determined by the split ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c82b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.sort_values(by=['startYear', '_orig_order'])\n",
    "# Calculate the split index\n",
    "split_index = int(len(data) * split_ratio)\n",
    "# Determine the split year\n",
    "split_year = data.iloc[split_index]['startYear']\n",
    "# Split the dataframe\n",
    "df_train = data[data['startYear'] < split_year]\n",
    "df_test  = data[data['startYear'] >= split_year]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e1a99b9",
   "metadata": {},
   "source": [
    "# Preparing training set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56347138",
   "metadata": {},
   "source": [
    "### Handle missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1aac8c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ander\\AppData\\Local\\Temp\\ipykernel_16528\\3696875169.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column] = (df[column]\n",
      "C:\\Users\\ander\\AppData\\Local\\Temp\\ipykernel_16528\\724404360.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train['runtimeMinutes'] = df_train['runtimeMinutes'].fillna(0)\n"
     ]
    }
   ],
   "source": [
    "# Fills missing director values\n",
    "df_train = handle_missing_director_value(df_train)\n",
    "# Fills missing actor values\n",
    "df_train = handle_missing_actor_value(df_train, num_actors)\n",
    "# Fills the missing runtimeMinutes with the mean of the whole startYear\n",
    "df_train = fill_mean(df_train, 'runtimeMinutes', 'startYear')\n",
    "# Fills in missing values with zero if there aren't any movies from the year with a runtime (2 rows)\n",
    "df_train['runtimeMinutes'] = df_train['runtimeMinutes'].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3448c6e7",
   "metadata": {},
   "source": [
    "### One hot encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0b7346",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ander\\AppData\\Local\\Temp\\ipykernel_16528\\1915589023.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['runtime_category'] = pd.cut(df[column_name], bins=bins, labels=labels, right=False)\n"
     ]
    }
   ],
   "source": [
    "# Categorize the runtime into the different bins defined in the function\n",
    "df_train = categorize_runtime(df_train, 'runtimeMinutes')\n",
    "# One hot encodes the genres and the runtime \n",
    "df_train[\"genres_list\"] = df_train[\"genres_list\"].apply(\n",
    "    lambda lst: [g for g in lst if g != \"\\\\N\"]\n",
    ")\n",
    "\n",
    "# Fit MultiLabelBinarizer on training data\n",
    "mlb = MultiLabelBinarizer()\n",
    "genre_encoded = mlb.fit_transform(df_train[\"genres_list\"])\n",
    "\n",
    "genre_df = pd.DataFrame(\n",
    "    genre_encoded,\n",
    "    columns=[f\"genre_{g.lower().replace(' ', '_')}\" for g in mlb.classes_],\n",
    "    index=df_train.index\n",
    ")\n",
    "\n",
    "\n",
    "df_train = pd.concat([df_train.drop(columns=[\"genres_list\"]), genre_df], axis=1)\n",
    "df_train, runtime_encoder = one_hot_encode_columns(df_train, ['runtime_category'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3231a7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorts the data to keep the temporal order\n",
    "df_train = df_train.sort_values(by=['startYear', '_orig_order'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b582630d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removes rows where the movie isn't present\n",
    "df_train = df_train.dropna(subset=['tconst'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e02ddc5d",
   "metadata": {},
   "source": [
    "### Drop columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607067d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = remove_actors_columns(df_train, num_actors)\n",
    "df_train = df_train.drop(columns=columns_to_drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea5f3999",
   "metadata": {},
   "source": [
    "Saves the data to the folder data inside the folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5473cef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "saveTrainingDatasetAt = r'.\\data\\training_dataset.csv' if useBackslash else r'./data/training_dataset.csv'\n",
    "df_train.to_csv(saveTrainingDatasetAt, sep =';')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a33aef",
   "metadata": {},
   "source": [
    "# Preparing test set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b1e199f",
   "metadata": {},
   "source": [
    "### Handle missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76cf22e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ander\\AppData\\Local\\Temp\\ipykernel_16528\\3696875169.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column] = (df[column]\n"
     ]
    }
   ],
   "source": [
    "# Fills missing director values\n",
    "df_test = handle_missing_director_value(df_test)\n",
    "# Fills missing actor values\n",
    "df_test = handle_missing_actor_value(df_test, num_actors)\n",
    "# Fills the missing runtimeMinutes with the mean of the whole startYear\n",
    "df_test = fill_mean(df_test, 'runtimeMinutes', 'startYear')\n",
    "# Fills in missing values with zero if there aren't any movies from the year with a runtime (0 rows)\n",
    "df_train['runtimeMinutes'] = df_train['runtimeMinutes'].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c9c568",
   "metadata": {},
   "source": [
    "### One hot encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6b928f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ander\\AppData\\Local\\Temp\\ipykernel_16528\\1915589023.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['runtime_category'] = pd.cut(df[column_name], bins=bins, labels=labels, right=False)\n"
     ]
    }
   ],
   "source": [
    "# Categorize the runtime into the different bins defined in the function\n",
    "df_test = categorize_runtime(df_test, 'runtimeMinutes')\n",
    "# One hot encodes the genres and the runtime \n",
    "df_test[\"genres_list\"] = df_test[\"genres_list\"].apply(\n",
    "    lambda lst: [g for g in lst if g != \"\\\\N\"]\n",
    ")\n",
    "\n",
    "# Use the same MultiLabelBinarizer fitted on training data (transform only, don't fit)\n",
    "genre_encoded = mlb.transform(df_test[\"genres_list\"])\n",
    "\n",
    "genre_df_test = pd.DataFrame(\n",
    "    genre_encoded,\n",
    "    columns=[f\"genre_{g.lower().replace(' ', '_')}\" for g in mlb.classes_],\n",
    "    index=df_test.index\n",
    ")\n",
    "\n",
    "df_test = pd.concat([df_test.drop(columns=[\"genres_list\"]), genre_df_test], axis=1)\n",
    "# Use the same runtime encoder fitted on training data\n",
    "df_test, _ = one_hot_encode_columns(df_test, ['runtime_category'], encoder=runtime_encoder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b3248f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removes rows where the movie isn't present\n",
    "df_test = df_test.dropna(subset=['tconst'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "094d96df",
   "metadata": {},
   "source": [
    "### Drop columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1b9c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = remove_actors_columns(df_test, num_actors)\n",
    "df_test = df_test.drop(columns=columns_to_drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c868d6",
   "metadata": {},
   "source": [
    "### Align the columns from the training data with the test data\n",
    "This is done for the to dataframe to have the same dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f3f1c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = align_columns(df_train, df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10170824",
   "metadata": {},
   "source": [
    "### Saves the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75cacb50",
   "metadata": {},
   "outputs": [],
   "source": [
    "saveTestDatasetAt = r'.\\data\\test_dataset.csv' if useBackslash else r'./data/test_dataset.csv'\n",
    "df_test.to_csv(saveTestDatasetAt, sep =';')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
