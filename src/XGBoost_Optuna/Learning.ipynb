{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8660fb70",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'optuna'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01moptuna\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mxgboost\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m XGBRegressor\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodel_selection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TimeSeriesSplit\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'optuna'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import optuna\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8bece70",
   "metadata": {},
   "source": [
    "## Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a192c846",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = ['Unnamed: 0', 'averageRating', 'numVotes', '_orig_order']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4afe9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_SPLITS = 5\n",
    "EARLY_STOPPING_ROUNDS = 200\n",
    "N_TRIALS = 50\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=N_SPLITS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e7b12c",
   "metadata": {},
   "source": [
    "### Retrieve data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e7596f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\".\\data\\training_dataset.csv\", sep=\";\")\n",
    "df = df.sort_values(by=['startYear', '_orig_order'])\n",
    "df = df.drop(columns=cols_to_drop)\n",
    "y = df[\"movie_score\"].values\n",
    "X = df.drop(columns=[\"movie_score\"])  # + your drop columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9049705f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    params = {\n",
    "        # Large number â€“ early stopping decides actual trees\n",
    "        \"n_estimators\": 50_000,\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.2),\n",
    "\n",
    "        # Tree structure\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 2, 10),\n",
    "        \"min_child_weight\": trial.suggest_int(\"min_child_weight\", 1, 10),\n",
    "\n",
    "        # Sampling\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.5, 1.0),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.5, 1.0),\n",
    "\n",
    "        # Regularization\n",
    "        \"gamma\": trial.suggest_float(\"gamma\", 0.0, 1.0),\n",
    "        \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 0.0, 1.0),\n",
    "        \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 0.5, 2.0),\n",
    "\n",
    "        # Long-tail friendly loss\n",
    "        \"objective\": \"reg:pseudohubererror\",\n",
    "\n",
    "        # Performance / reproducibility\n",
    "        \"random_state\": 42,\n",
    "        \"n_jobs\": -1,\n",
    "        \"tree_method\": \"hist\",\n",
    "        \"device\": \"cuda\",\n",
    "    }\n",
    "\n",
    "    fold_rmses = []\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(tscv.split(X), start=1):\n",
    "        X_train, X_val = X[train_idx], X[val_idx]\n",
    "        y_train, y_val = y[train_idx], y[val_idx]\n",
    "\n",
    "        model = XGBRegressor(**params)\n",
    "\n",
    "        model.fit(\n",
    "            X_train, y_train,\n",
    "            eval_set=[(X_val, y_val)],\n",
    "            early_stopping_rounds=EARLY_STOPPING_ROUNDS,\n",
    "            verbose=False,\n",
    "        )\n",
    "\n",
    "        preds = model.predict(X_val)\n",
    "        rmse = mean_squared_error(y_val, preds, squared=False)\n",
    "        fold_rmses.append(rmse)\n",
    "\n",
    "        # Report intermediate result (enables pruning)\n",
    "        trial.report(np.mean(fold_rmses), step=fold)\n",
    "        if trial.should_prune():\n",
    "            raise optuna.TrialPruned()\n",
    "\n",
    "    return float(np.mean(fold_rmses))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2376aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_optimization_history(study)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cfcc092",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_param_importances(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7dfa62",
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study(\n",
    "    direction=\"minimize\",\n",
    "    sampler=optuna.samplers.TPESampler(seed=42),\n",
    ")\n",
    "\n",
    "study.optimize(objective, n_trials=N_TRIALS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3d96ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = study.best_params\n",
    "\n",
    "final_model = XGBRegressor(\n",
    "    **best_params,\n",
    "    n_estimators=50_000,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    tree_method=\"hist\",\n",
    "    device=\"cuda\",\n",
    ")\n",
    "\n",
    "split = int(len(X) * 0.85)\n",
    "\n",
    "final_model.fit(\n",
    "    X[:split], y[:split],\n",
    "    eval_set=[(X[split:], y[split:])],\n",
    "    early_stopping_rounds=EARLY_STOPPING_ROUNDS,\n",
    "    verbose=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead9c8d0",
   "metadata": {},
   "source": [
    "### Train the best model with parameters and save it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9d742f",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = final_model.best_iteration\n",
    "\n",
    "# Refit best model on ALL data\n",
    "best_model.fit(X, y, verbose=False)\n",
    "# Save the model\n",
    "joblib.dump(best_model, \"xgb_reg_movie_log_transformed.joblib\")\n",
    "\n",
    "# Saves the best parameters and tried parameters to csv file\n",
    "cv_results = pd.DataFrame(search.cv_results_)\n",
    "cv_results.to_csv(r\".\\data\\xgb_reg_movie_log_transformed.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
